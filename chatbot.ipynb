{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv\n",
    "\n",
    "import os\n",
    "cohere_api_key = os.getenv(\"COHERE_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_cohere import ChatCohere\n",
    "chat = ChatCohere(cohere_api_key=cohere_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example = {\n",
    "    \"career\": \"AI-Driven Marketing Analyst\",\n",
    "    \"description\": \"This role combines your interest in marketing and sales with your love for data and trends, leveraging AI tools to analyze consumer behavior, optimize campaigns, and predict market trends. It’s a perfect bridge from a non-technical commerce background to a technical AI-focused career.\",\n",
    "    \"specializations\": [\n",
    "        \"Predictive Analytics in Marketing\",\n",
    "        \"Customer Behavior Modeling using AI\",\n",
    "        \"AI-Powered Campaign Optimization\",\n",
    "        \"Marketing Automation with AI Tools\",\n",
    "        \"Data-Driven Sales Strategy using Machine Learning\"\n",
    "    ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def counselor(user_details):\n",
    "    template = f'''\n",
    "    You are a professional career counselor that talks to the user. Your job is to help transition the user into the field of Artificial Intelligence.\n",
    "    Important - Answer to the point, keep it concise and only answer what is asked. \n",
    "    User profile - \n",
    "    {user_details}\n",
    "\n",
    "    You will recieve a user profile, your job is to -\n",
    "    1. Tell me a career that maps perfectly with the provided options given the user wants to transition from a non technical to a technical background.\n",
    "    2. Tell me specializations that the user can do for the suggested career.\n",
    "\n",
    "    Provide the answer in the following format like this example - \n",
    "    {example}\n",
    "    '''\n",
    "    response = chat.invoke(template).content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_roadmap = {\n",
    "    \"roadmap\": \"write detailed roadmap here\",\n",
    "    \"tools and skills required\": \"List them here\",\n",
    "    \"how to create a portfolio and become job ready\": \"Detailed description\",\n",
    "    \"salary hike\" : \"if available\"\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "def roadmap_generator(career, specialization, time, current_salary):\n",
    "    template = f'''\n",
    "    You are a professional career counselor, your client wants to pursue a career in {career},\n",
    "    with specialization in {specialization}. Your client can only spare {time} hours per week to up skill,\n",
    "    and client's current salary is Rs. {current_salary}/annum.\n",
    "\n",
    "    Your job is to:\n",
    "    1. Generate a specialized roadmap adhering strictly to the specialization and time mentioned.\n",
    "    2. List all the necessary tools and skills required.\n",
    "    3. Suggest how to create a portfolio, so that client can become job ready.\n",
    "    4. Expected salary hike if the client switches into new role if current annual salary provided.\n",
    "\n",
    "    Provide the answer strictly in curly braces without using any special characters - \n",
    "    {example_roadmap}\n",
    "\n",
    "    '''\n",
    "    response = chat.invoke(template).content\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = roadmap_generator(\"data scientist\", \" behaviour analysis\", \"25\", \"4lpa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "string = string.replace(\"\\n\",\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'roadmap': 'Week 1-2: Learn Python programming fundamentals including data structures, functions, and basic libraries like NumPy and Pandas. Week 3-4: Study statistics and probability focusing on descriptive and inferential statistics, hypothesis testing, and regression analysis. Week 5-6: Dive into data preprocessing techniques such as data cleaning, handling missing values, and feature engineering. Week 7-8: Explore machine learning algorithms for behavior analysis, including classification, clustering, and recommendation systems. Week 9-10: Learn data visualization tools like Matplotlib, Seaborn, and Plotly to represent behavioral data effectively. Week 11-12: Study behavioral analytics concepts, user segmentation, and customer journey analysis. Week 13-14: Work on real-world datasets to apply learned techniques and build a foundational portfolio. Week 15-16: Focus on advanced topics like natural language processing (NLP) for text-based behavior analysis. Week 17-18: Learn deep learning basics using TensorFlow or PyTorch for behavioral pattern recognition. Week 19-20: Develop a capstone project integrating all skills, focusing on a specific behavior analysis problem. Week 21-24: Enhance portfolio with diverse projects, participate in hackathons, and contribute to open-source projects. Week 25: Prepare for interviews by practicing technical and behavioral questions, and networking with industry professionals.','tools and skills required': 'Python, NumPy, Pandas, Matplotlib, Seaborn, Plotly, Scikit-learn, TensorFlow, PyTorch, SQL, Statistics, Probability, Machine Learning, Deep Learning, Data Preprocessing, Data Visualization, Behavioral Analytics, NLP, Git, Jupyter Notebook, Excel, Power BI or Tableau','how to create a portfolio and become job ready': 'Build a GitHub repository showcasing projects with clear documentation and code. Include diverse projects like customer churn prediction, sentiment analysis, and user segmentation. Write blog posts explaining project methodologies and insights. Participate in Kaggle competitions to gain practical experience. Network on LinkedIn, join data science communities, and attend webinars. Create a personal website highlighting skills, projects, and achievements. Seek internships or freelance work to gain industry experience. Prepare a tailored resume and cover letter for each job application.','salary hike': 'Expected salary hike ranges from Rs. 8lpa to Rs. 12lpa depending on location, company, and negotiation skills.'}\""
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'roadmap': 'Week 1-2: Learn Python programming fundamentals including data structures, functions, and basic libraries like NumPy and Pandas. Week 3-4: Study statistics and probability focusing on descriptive and inferential statistics, hypothesis testing, and regression analysis. Week 5-6: Dive into data preprocessing techniques such as data cleaning, handling missing values, and feature engineering. Week 7-8: Explore machine learning algorithms for behavior analysis, including classification, clustering, and recommendation systems. Week 9-10: Learn data visualization tools like Matplotlib, Seaborn, and Plotly to represent behavioral data effectively. Week 11-12: Study behavioral analytics concepts, user segmentation, and customer journey analysis. Week 13-14: Work on real-world datasets to apply learned techniques and build a foundational portfolio. Week 15-16: Focus on advanced topics like natural language processing (NLP) for text-based behavior analysis. Week 17-18: Learn deep learning basics using TensorFlow or PyTorch for behavioral pattern recognition. Week 19-20: Develop a capstone project integrating all skills, focusing on a specific behavior analysis problem. Week 21-24: Enhance portfolio with diverse projects, participate in hackathons, and contribute to open-source projects. Week 25: Prepare for interviews by practicing technical and behavioral questions, and networking with industry professionals.',\n",
       " 'tools and skills required': 'Python, NumPy, Pandas, Matplotlib, Seaborn, Plotly, Scikit-learn, TensorFlow, PyTorch, SQL, Statistics, Probability, Machine Learning, Deep Learning, Data Preprocessing, Data Visualization, Behavioral Analytics, NLP, Git, Jupyter Notebook, Excel, Power BI or Tableau',\n",
       " 'how to create a portfolio and become job ready': 'Build a GitHub repository showcasing projects with clear documentation and code. Include diverse projects like customer churn prediction, sentiment analysis, and user segmentation. Write blog posts explaining project methodologies and insights. Participate in Kaggle competitions to gain practical experience. Network on LinkedIn, join data science communities, and attend webinars. Create a personal website highlighting skills, projects, and achievements. Seek internships or freelance work to gain industry experience. Prepare a tailored resume and cover letter for each job application.',\n",
       " 'salary hike': 'Expected salary hike ranges from Rs. 8lpa to Rs. 12lpa depending on location, company, and negotiation skills.'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "ast.literal_eval(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 3) (<unknown>, line 3)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[1;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[0;32mf:\\Users\\MSI\\miniconda3\\envs\\lanchain_env\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3577\u001b[0m in \u001b[0;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[0;32mIn[39], line 2\u001b[0m\n    ast.literal_eval(\u001b[0m\n",
      "\u001b[0m  File \u001b[0;32mf:\\Users\\MSI\\miniconda3\\envs\\lanchain_env\\lib\\ast.py:64\u001b[0m in \u001b[0;35mliteral_eval\u001b[0m\n    node_or_string = parse(node_or_string.lstrip(\" \\t\"), mode='eval')\u001b[0m\n",
      "\u001b[1;36m  File \u001b[1;32mf:\\Users\\MSI\\miniconda3\\envs\\lanchain_env\\lib\\ast.py:50\u001b[1;36m in \u001b[1;35mparse\u001b[1;36m\n\u001b[1;33m    return compile(source, filename, mode, flags,\u001b[1;36m\n",
      "\u001b[1;36m  File \u001b[1;32m<unknown>:3\u001b[1;36m\u001b[0m\n\u001b[1;33m    'roadmap': '**Week 1-4: Foundations of Business Analysis & Behavior Analysis**\u001b[0m\n\u001b[1;37m               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unterminated string literal (detected at line 3)\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "ast.literal_eval(\n",
    "    '''\n",
    "{\n",
    "  'roadmap': '**Week 1-4: Foundations of Business Analysis & Behavior Analysis**  \n",
    "- **Hours/Week:** 25  \n",
    "- **Focus:**  \n",
    "  - Study core concepts of Business Analysis (BA) using IIBA BABOK guide (5 hours).  \n",
    "  - Learn basics of Behavior Analysis (e.g., ABA principles, behavioral psychology) via online courses (Coursera, Udemy - 10 hours).  \n",
    "  - Start building foundational skills in data analysis (Excel, basic SQL - 10 hours).  \n",
    "\n",
    "**Week 5-12: Intermediate Skills & Tool Proficiency**  \n",
    "- **Hours/Week:** 25  \n",
    "- **Focus:**  \n",
    "  - Master advanced Excel (pivot tables, macros) and SQL for data manipulation (10 hours).  \n",
    "  - Learn Python for data analysis (Pandas, NumPy) and visualization (Matplotlib, Seaborn - 10 hours).  \n",
    "  - Study behavior analysis tools (e.g., functional behavior assessment, data collection methods - 5 hours).  \n",
    "\n",
    "**Week 13-20: Specialization & Application**  \n",
    "- **Hours/Week:** 25  \n",
    "- **Focus:**  \n",
    "  - Integrate BA and behavior analysis: Learn to apply behavioral insights to business problems (e.g., customer behavior, employee productivity - 10 hours).  \n",
    "  - Work on mini-projects combining data analysis and behavior analysis (e.g., analyzing customer churn using behavioral data - 10 hours).  \n",
    "  - Start building a portfolio (5 hours).  \n",
    "\n",
    "**Week 21-25: Advanced Learning & Job Readiness**  \n",
    "- **Hours/Week:** 25  \n",
    "- **Focus:**  \n",
    "  - Learn advanced tools like Tableau/Power BI for visualization (10 hours).  \n",
    "  - Study soft skills for BAs (stakeholder management, requirement gathering - 5 hours).  \n",
    "  - Complete portfolio projects and prepare for interviews (10 hours).',\n",
    "\n",
    "  'tools and skills required': '**Technical Tools:**  \n",
    "  - Excel (Advanced)  \n",
    "  - SQL  \n",
    "  - Python (Pandas, NumPy, Matplotlib, Seaborn)  \n",
    "  - Tableau/Power BI  \n",
    "  - Behavior Analysis Tools (e.g., data collection apps, FBA software)  \n",
    "\n",
    "**Skills:**  \n",
    "  - Data Analysis & Interpretation  \n",
    "  - Behavioral Psychology Principles  \n",
    "  - Requirement Gathering & Stakeholder Management  \n",
    "  - Problem-Solving & Critical Thinking  \n",
    "  - Communication & Presentation Skills',\n",
    "\n",
    "  'how to create a portfolio and become job ready': '**Portfolio Creation:**  \n",
    "1. **Projects:** Include 3-4 projects showcasing BA and behavior analysis skills. Examples:  \n",
    "   - Analyze employee productivity using behavioral data.  \n",
    "   - Predict customer behavior using Python and SQL.  \n",
    "   - Visualize behavioral trends in Tableau/Power BI.  \n",
    "2. **Case Studies:** Document real-world scenarios where you applied behavioral insights to business problems.  \n",
    "3. **GitHub/Website:** Host your projects on GitHub or a personal website for visibility.  \n",
    "\n",
    "**Job Readiness:**  \n",
    "1. **Networking:** Join BA and behavior analysis communities (LinkedIn, forums).  \n",
    "2. **Mock Interviews:** Practice BA and behavior analysis interview questions.  \n",
    "3. **Resume Tailoring:** Highlight specialized skills and portfolio projects.  \n",
    "4. **Certifications:** Consider certifications like CCBA (Certification of Capability in Business Analysis) or ABA-related certifications.',\n",
    "\n",
    "  'salary hike': 'Expected salary hike: **50-70%** (Rs. 6-7 LPA/annum) depending on the company, location, and negotiation skills.'\n",
    "}'''\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = counselor('''Educational Background: arts\n",
    "Interest: reading books\n",
    "Comfort with Data: Love working with data & trends\n",
    "Goal: Switching to a new domain\n",
    "Learning Style: Books & Research Papers\n",
    "Hours per Week: 10\n",
    "Current Salary: 50000\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'career': 'AI Content Strategist',\n",
       " 'description': 'This role blends your arts background and love for reading with your interest in data and trends, using AI tools to create, analyze, and optimize content strategies. It’s an ideal transition into a technical AI-focused career while leveraging your strengths.',\n",
       " 'specializations': ['Natural Language Processing (NLP) for Content Creation',\n",
       "  'AI-Driven Content Analytics',\n",
       "  'Trend Analysis in Content Strategy',\n",
       "  'Personalized Content Recommendations using AI',\n",
       "  'Ethical AI in Content Generation']}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "ast.literal_eval(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting specialized learning roadmap\n",
    "# 1. generate a specialized leanring roadmap\n",
    "# 2. Search google with the roadmap to get links for videos\n",
    "# 3. List available fresher jobs\n",
    "# 4. Suggest coaching classes and people to connect with based on ip address\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict(\n",
      "career = \"AI Content Strategist\",\n",
      "description = \"This role leverages your arts background and love for reading, combining it with your interest in data and trends. As an AI Content Strategist, you'll use AI tools to analyze content performance, identify trends, and create data-driven content strategies. It's an ideal transition into a technical AI-focused career while utilizing your non-technical skills.\",\n",
      "specializations = [\n",
      "    \"Natural Language Processing (NLP) for Content Creation\",\n",
      "    \"AI-Powered Content Personalization\",\n",
      "    \"Data-Driven Content Optimization\",\n",
      "    \"Trend Analysis and Forecasting in Content Strategy\",\n",
      "    \"AI-Generated Content and Ethics\"\n",
      "]\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "answer = counselor('''Educational Background: arts\n",
    "Interest: reading books\n",
    "Comfort with Data: Love working with data & trends\n",
    "Goal: Switching to a new domain\n",
    "Learning Style: Books & Research Papers\n",
    "Hours per Week: 10\n",
    "Current Salary: 50000\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "malformed node or string on line 3: <ast.Name object at 0x000002A4D6C66E60>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 8\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mast\u001b[39;00m\n\u001b[0;32m      2\u001b[0m data_string \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124m{\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124m    suggested_career_path: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHealth Data Analyst\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124m    why_it_was_suggested: \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCombines your commerce background, interest in healthcare, and love for working with data & trends. Its a technical role that bridges healthcare and data analysis, perfect for a domain switch.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;124m}\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m----> 8\u001b[0m string \u001b[38;5;241m=\u001b[39m \u001b[43mast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mliteral_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_string\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\Users\\MSI\\miniconda3\\envs\\lanchain_env\\lib\\ast.py:110\u001b[0m, in \u001b[0;36mliteral_eval\u001b[1;34m(node_or_string)\u001b[0m\n\u001b[0;32m    108\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m left \u001b[38;5;241m-\u001b[39m right\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _convert_signed_num(node)\n\u001b[1;32m--> 110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_or_string\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\Users\\MSI\\miniconda3\\envs\\lanchain_env\\lib\\ast.py:99\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(node\u001b[38;5;241m.\u001b[39mkeys) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(node\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[0;32m     98\u001b[0m         _raise_malformed_node(node)\n\u001b[1;32m---> 99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_convert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_convert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, BinOp) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node\u001b[38;5;241m.\u001b[39mop, (Add, Sub)):\n\u001b[0;32m    102\u001b[0m     left \u001b[38;5;241m=\u001b[39m _convert_signed_num(node\u001b[38;5;241m.\u001b[39mleft)\n",
      "File \u001b[1;32mf:\\Users\\MSI\\miniconda3\\envs\\lanchain_env\\lib\\ast.py:109\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    108\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m left \u001b[38;5;241m-\u001b[39m right\n\u001b[1;32m--> 109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert_signed_num\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\Users\\MSI\\miniconda3\\envs\\lanchain_env\\lib\\ast.py:83\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert_signed_num\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     82\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m operand\n\u001b[1;32m---> 83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert_num\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\Users\\MSI\\miniconda3\\envs\\lanchain_env\\lib\\ast.py:74\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert_num\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_convert_num\u001b[39m(node):\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, Constant) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(node\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mcomplex\u001b[39m):\n\u001b[1;32m---> 74\u001b[0m         \u001b[43m_raise_malformed_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m node\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[1;32mf:\\Users\\MSI\\miniconda3\\envs\\lanchain_env\\lib\\ast.py:71\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._raise_malformed_node\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lno \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(node, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlineno\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     70\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m on line \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlno\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 71\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: malformed node or string on line 3: <ast.Name object at 0x000002A4D6C66E60>"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "data_string = \"\"\"\n",
    "{\n",
    "    suggested_career_path: 'Health Data Analyst',\n",
    "    why_it_was_suggested: 'Combines your commerce background, interest in healthcare, and love for working with data & trends. Its a technical role that bridges healthcare and data analysis, perfect for a domain switch.'\n",
    "}\n",
    "\"\"\"\n",
    "string = ast.literal_eval(data_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "malformed node or string on line 2: <ast.Name object at 0x000002A9265A4250>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[39], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# 2️⃣ Extract list content\u001b[39;00m\n\u001b[0;32m     22\u001b[0m list_match \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecializations\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*=\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124ms*(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m[.*?\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m])\u001b[39m\u001b[38;5;124m\"\u001b[39m, data_string, re\u001b[38;5;241m.\u001b[39mDOTALL)\n\u001b[1;32m---> 24\u001b[0m career_suggestion \u001b[38;5;241m=\u001b[39m \u001b[43mast\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mliteral_eval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdict_match\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m dict_match \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m     25\u001b[0m specializations \u001b[38;5;241m=\u001b[39m ast\u001b[38;5;241m.\u001b[39mliteral_eval(list_match\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;28;01mif\u001b[39;00m list_match \u001b[38;5;28;01melse\u001b[39;00m []\n",
      "File \u001b[1;32mf:\\Users\\MSI\\miniconda3\\envs\\lanchain_env\\lib\\ast.py:110\u001b[0m, in \u001b[0;36mliteral_eval\u001b[1;34m(node_or_string)\u001b[0m\n\u001b[0;32m    108\u001b[0m                 \u001b[38;5;28;01mreturn\u001b[39;00m left \u001b[38;5;241m-\u001b[39m right\n\u001b[0;32m    109\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _convert_signed_num(node)\n\u001b[1;32m--> 110\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_or_string\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\Users\\MSI\\miniconda3\\envs\\lanchain_env\\lib\\ast.py:99\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(node\u001b[38;5;241m.\u001b[39mkeys) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(node\u001b[38;5;241m.\u001b[39mvalues):\n\u001b[0;32m     98\u001b[0m         _raise_malformed_node(node)\n\u001b[1;32m---> 99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_convert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    100\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m_convert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, BinOp) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node\u001b[38;5;241m.\u001b[39mop, (Add, Sub)):\n\u001b[0;32m    102\u001b[0m     left \u001b[38;5;241m=\u001b[39m _convert_signed_num(node\u001b[38;5;241m.\u001b[39mleft)\n",
      "File \u001b[1;32mf:\\Users\\MSI\\miniconda3\\envs\\lanchain_env\\lib\\ast.py:109\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    108\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m left \u001b[38;5;241m-\u001b[39m right\n\u001b[1;32m--> 109\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert_signed_num\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\Users\\MSI\\miniconda3\\envs\\lanchain_env\\lib\\ast.py:83\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert_signed_num\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     82\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39m operand\n\u001b[1;32m---> 83\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_convert_num\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mf:\\Users\\MSI\\miniconda3\\envs\\lanchain_env\\lib\\ast.py:74\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._convert_num\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_convert_num\u001b[39m(node):\n\u001b[0;32m     73\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(node, Constant) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(node\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;28mint\u001b[39m, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mcomplex\u001b[39m):\n\u001b[1;32m---> 74\u001b[0m         \u001b[43m_raise_malformed_node\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     75\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m node\u001b[38;5;241m.\u001b[39mvalue\n",
      "File \u001b[1;32mf:\\Users\\MSI\\miniconda3\\envs\\lanchain_env\\lib\\ast.py:71\u001b[0m, in \u001b[0;36mliteral_eval.<locals>._raise_malformed_node\u001b[1;34m(node)\u001b[0m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lno \u001b[38;5;241m:=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(node, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlineno\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     70\u001b[0m     msg \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m on line \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlno\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 71\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnode\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mValueError\u001b[0m: malformed node or string on line 2: <ast.Name object at 0x000002A9265A4250>"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "import re\n",
    "\n",
    "data_string = \"\"\"\n",
    "career_suggestion = {\n",
    "    suggested_career_path: 'Health Data Analyst',\n",
    "    why_it_was_suggested: 'Combines your commerce background, interest in healthcare, and love for working with data & trends. Its a technical role that bridges healthcare and data analysis, perfect for a domain switch.'\n",
    "}\n",
    "\n",
    "specializations = [\n",
    "    'Clinical Data Analysis',\n",
    "    'Healthcare Informatics',\n",
    "    'Public Health Data Analytics',\n",
    "    'Health Economics and Outcomes Research (HEOR)',\n",
    "    'Epidemiological Data Analysis'\n",
    "]\n",
    "\"\"\"\n",
    "# 1️⃣ Extract dictionary content\n",
    "dict_match = re.search(r\"career_suggestion\\s*=\\s*({.*?})\", data_string, re.DOTALL)\n",
    "\n",
    "# 2️⃣ Extract list content\n",
    "list_match = re.search(r\"specializations\\s*=\\s*(\\[.*?\\])\", data_string, re.DOTALL)\n",
    "\n",
    "career_suggestion = ast.literal_eval(dict_match.group(1)) if dict_match else {}\n",
    "specializations = ast.literal_eval(list_match.group(1)) if list_match else []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(1, 296), match=\"career_suggestion = {\\n    suggested_career_path:>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict_match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Given your background in **Home Science**, interest in **Customer Behavior & Market Trends**, limited comfort with data, and goal of **career growth in your current field**, a career that maps perfectly to your profile while transitioning from a non-technical to a technical background is:\n",
      "\n",
      "**Consumer Insights Analyst (with a focus on Market Research and Data-Driven Decision Making)**\n",
      "\n",
      "Here's how this career aligns with your options:\n",
      "\n",
      "1. **Leveraging Home Science Background**:  \n",
      "   Your understanding of consumer behavior, lifestyle, and preferences from Home Science can be directly applied to analyzing market trends and consumer insights in industries like retail, FMCG, or lifestyle products.\n",
      "\n",
      "2. **Interest in Customer Behavior & Market Trends**:  \n",
      "   This role focuses on understanding consumer preferences, market dynamics, and trends, which aligns perfectly with your interests.\n",
      "\n",
      "3. **Transition to Technical Skills**:  \n",
      "   While you’re not very comfortable with data, this role requires basic to intermediate technical skills (e.g., data analysis, visualization tools like Excel, Tableau, or Google Analytics). You can start with beginner-friendly tools and gradually build expertise through **online courses and video tutorials**, which match your preferred learning style.\n",
      "\n",
      "4. **Career Growth in Current Field**:  \n",
      "   By adding technical skills to your existing knowledge of consumer behavior, you can position yourself for growth in market research, product development, or marketing roles within industries related to Home Science.\n",
      "\n",
      "5. **Time Commitment**:  \n",
      "   With **10 hours per week**, you can dedicate time to learning foundational technical skills (e.g., data analysis, basic programming like Python for data analysis) while applying them to real-world projects in your field.\n",
      "\n",
      "**Steps to Transition:**\n",
      "- **Learn Data Analysis Basics**: Start with Excel, Google Sheets, or introductory courses on data analysis.  \n",
      "- **Explore Consumer Insights Tools**: Learn tools like Tableau, Power BI, or Google Analytics for visualizing consumer data.  \n",
      "- **Take Market Research Courses**: Focus on courses that teach consumer behavior analysis and market trends.  \n",
      "- **Apply Skills to Home Science Context**: Work on projects or case studies related to consumer goods, lifestyle products, or home-related industries.  \n",
      "\n",
      "This career path allows you to stay connected to your current field while gaining technical skills that are highly valued in today’s job market.\n"
     ]
    }
   ],
   "source": [
    "print(chat.invoke('''\n",
    "tell me a carrer that maps perfectly with the provided options given the user wants to transition from a non technical to a technical background\n",
    "- Educational Background: home science\n",
    "Interest: Customer Behavior & Market Trends\n",
    "Comfort with Data: Not very comfortable\n",
    "Goal: Career growth in current field\n",
    "Learning Style: Videos & Online Courses\n",
    "Hours per Week: 10\n",
    "''').content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "subject=\"Python NLTK spaCy TextBlob Pandas NumPy Scikit-learn TensorFlow Keras Jupyter Notebook Git GitHub Basic machine learning concepts Data preprocessing Text analysis Sentiment analysis\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from phi.agent import Agent,RunResponse\n",
    "from phi.tools.googlesearch import GoogleSearch\n",
    "from phi.model.cohere import CohereChat\n",
    "chat = CohereChat(api_key=\"cZWxyHPX5B72hYVgeLK45bTrwiM05v8lQ5dHGIXS\")\n",
    "\n",
    "agent = Agent(\n",
    "    provider=chat,\n",
    "    tools=[GoogleSearch()],\n",
    "    description=f\"You are a youtube video link provider to assist in study for the following subjects - {subject}\",\n",
    "    instructions=[\n",
    "        \"Given a request provide relevant youtube links\",\n",
    "        \"Make sure the videos are of the specific topic only\",\n",
    "        \"Search in English\",\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I will search for the best x-ray facility in Bhopal and then select the top 4 results to include in my answer.\n",
      "\n",
      "Here are four of the best-rated X-ray facilities in Bhopal:\n",
      "1. Sanket MRI Centre\n",
      "2. Sanket Diagnostic Centre\n",
      "3. Venkatesh Diagnostic Center\n",
      "4. QURA DIAGNOSTICS AND RESEARCH CENTRE\n"
     ]
    }
   ],
   "source": [
    "response: RunResponse = agent.run(\"best xray facility in bhopal\")\n",
    "print(response.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gpu_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
